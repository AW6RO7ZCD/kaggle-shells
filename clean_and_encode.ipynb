{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean & Encode\n",
    "--------------\n",
    "\n",
    "<div style=\"text-align: justify\"> Data at <a href=\"https://www.kaggle.com/datasets/aw6ro7zcd/shells/versions/1\">kaggle.com/datasets/aw6ro7zcd/shells/versions/1</a> are mixed and include simplifications and some errors. The goal of this proceeding is to clean and prepare these data to be available to use and finally, encode them to reduce their size.\n",
    "\n",
    "Notice! If you want to run this notebook, at first you must download the data from the link above and put them into the \"./raw data/\" directory.\n",
    "\n",
    "The proceeding is finished by a new dataset that can be found with entire description at <a href=\"https://www.kaggle.com/datasets/aw6ro7zcd/shells/versions/2\">kaggle.com/datasets/aw6ro7zcd/shells/versions/2</a>.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import plotly.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT: str = './raw data/'\n",
    "COLUMNS: list[str] = ['Brightness',\n",
    "                      'Orientation',\n",
    "                      'Stripes',\n",
    "                      'AntiStripes',\n",
    "                      'CornerAngle',\n",
    "                      'DilationAngle',\n",
    "                      'Length',\n",
    "                      'Width',\n",
    "                      'Height']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] System nie może odnaleźć określonej ścieżki: './raw data/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pages_paths: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([ROOT, file_name])\\\n\u001b[1;32m----> 2\u001b[0m                           \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mROOT\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m pages_paths:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(path)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] System nie może odnaleźć określonej ścieżki: './raw data/'"
     ]
    }
   ],
   "source": [
    "pages_paths: list[str] = [''.join([ROOT, file_name])\\\n",
    "                          for file_name in os.listdir(ROOT)]\n",
    "                          \n",
    "for path in pages_paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages: list[pd.DataFrame] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. rebuild the first page of data\n",
    "\n",
    "<div style=\"text-align: justify\">Columns on the first page are mixed, it is necessary to fit them to the rest.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page: pd.DataFrame = pd.read_csv(filepath_or_buffer=pages_paths[0],\n",
    "                                 sep='\\t',\n",
    "                                 names=['Length',\n",
    "                                        'Width',\n",
    "                                        'Height',\n",
    "                                        'CornerAngle',\n",
    "                                        'Stripes',\n",
    "                                        'AntiStripes',\n",
    "                                        'Brightness', \n",
    "                                        'Orientation',\n",
    "                                        'DilationAngle'])\n",
    "\n",
    "page.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = page.reindex(columns=COLUMNS)\n",
    "\n",
    "page.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. concatenate all pages\n",
    "\n",
    "Now it is possible to merge all the pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queue the pages\n",
    "pages.append(page)      # the first page is already loaded\n",
    "for page_path in pages_paths[1:]:\n",
    "    pages.append(pd.read_csv(filepath_or_buffer=page_path,\n",
    "                             sep='\\t',\n",
    "                             names=COLUMNS))\n",
    "\n",
    "# merge all\n",
    "data: pd.DataFrame = pd.concat(objs=pages, ignore_index=True)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. apply uniform notation\n",
    "\n",
    "<div style=\"text-align: justify\">Some of columns include various types of values i.e. P, P', 1, 0 at Orientation. However, it is better to keep uniform notation.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values\n",
    "for column_name in data.columns:\n",
    "    print(column_name, ': ',data[column_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(value='', inplace=True)     # put empty string '' where cells are NaN\n",
    "for old, new in [('-', ''),\n",
    "                 ('L', '1'),\n",
    "                 ('D', '0'),\n",
    "                 ('P', '1'),\n",
    "                 ('P\\'', '0')]:\n",
    "    data.mask(cond=data == old, other=new, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values\n",
    "for column_name in data.columns:\n",
    "    print(column_name, ': ',data[column_name].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. set data types\n",
    "\n",
    "<div style=\"text-align: justify\">Now, values looks as they have same type of notation per column along all lines. However, there is still discrepancy in the case of cell types.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.applymap(lambda cell: str(cell).replace(',','.'))\n",
    "for column in data:\n",
    "    data[column] = pd.to_numeric(arg=data[column], errors='coerce')\n",
    "\n",
    "for column in data:\n",
    "    print(column,':', data[column].dtype)\n",
    "    print(sorted(data[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. overwrite values\n",
    "<div style=\"text-align: justify\">The last step gave opportunities to visualize the data.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    fig: go.Figure = go.Figure()\n",
    "    if column not in data.columns[:2]:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            y=data[column],\n",
    "            mode='markers',\n",
    "            marker=dict(size=3.5,color='black')))\n",
    "        fig.update_xaxes(title_text='index')\n",
    "        fig.update_yaxes(title_text=column)\n",
    "    else:\n",
    "        fig.add_trace(go.Histogram(\n",
    "            marker={'color':'black'},\n",
    "            x=data[column].astype(str),\n",
    "            histnorm='',\n",
    "            meta={'color':'black'}))\n",
    "        fig.update_xaxes(title_text='value')\n",
    "        fig.update_yaxes(title_text=column+' distribution')\n",
    "    fig.update_xaxes(\n",
    "        showticklabels=True,\n",
    "        zerolinecolor='#444',\n",
    "        linecolor=\"#000000\",\n",
    "        showline=True)\n",
    "    fig.update_yaxes(\n",
    "        showticklabels=True,\n",
    "        zerolinecolor='#444',\n",
    "        linecolor=\"#000000\",\n",
    "        showline=True)\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=\"rgba(255,255,255,0)\",\n",
    "        font_color=\"rgba(0,0,0,1)\",\n",
    "        paper_bgcolor=\"rgba(255,255,255,0)\",\n",
    "        showlegend=False,\n",
    "        width=480,\n",
    "        height=360,\n",
    "        margin=dict(l=0,r=0,b=0,t=0,pad=0))\n",
    "    fig.show(\"png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">These figures reveals some details. One of them is that dataset DilationsAngle includes well visible, random error arose during rewriting (digitalization) measurements.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix\n",
    "data.loc[data['DilationAngle'] == 800, 'DilationAngle'] = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'DilationAngle'\n",
    "fig: go.Figure = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=data[column],\n",
    "    mode='markers',\n",
    "    marker=dict(size=3.5,color='black')))\n",
    "fig.update_xaxes(\n",
    "    title_text='index',\n",
    "    showticklabels=True,\n",
    "    zerolinecolor='#444',\n",
    "    linecolor=\"#000000\",\n",
    "    showline=True)\n",
    "fig.update_yaxes(\n",
    "    title_text=column,\n",
    "    showticklabels=True,\n",
    "    zerolinecolor='#444',\n",
    "    linecolor=\"#000000\",\n",
    "    showline=True)\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"rgba(255,255,255,0)\",\n",
    "    font_color=\"rgba(0,0,0,1)\",\n",
    "    paper_bgcolor=\"rgba(255,255,255,0)\",\n",
    "    showlegend=False,\n",
    "    width=480,\n",
    "    height=360,\n",
    "    margin=dict(l=0,r=0,b=0,t=0,pad=0))\n",
    "fig.show('png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">The same figure has also a kind of dispersion that have to be immediately fixed. For records with indices greater than ~400, some of records reach values below 90 degrees. This is caused by changed notation during collecting the data. Namely, for indices smaller than ~400, a measured angle was rounded up, to 90 degrees.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['DilationAngle'] < 90.0, 'DilationAngle'] = \\\n",
    "    (data[data['DilationAngle'] < 90.0] + 100.0) -90.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'DilationAngle'\n",
    "fig: go.Figure = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    y=data[column],\n",
    "    mode='markers',\n",
    "    marker=dict(size=3.5,color='black')))\n",
    "fig.update_xaxes(\n",
    "    title_text='index',\n",
    "    showticklabels=True,\n",
    "    zerolinecolor='#444',\n",
    "    linecolor=\"#000000\",\n",
    "    showline=True)\n",
    "fig.update_yaxes(\n",
    "    title_text=column,\n",
    "    showticklabels=True,\n",
    "    zerolinecolor='#444',\n",
    "    linecolor=\"#000000\",\n",
    "    showline=True)\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"rgba(255,255,255,0)\",\n",
    "    font_color=\"rgba(0,0,0,1)\",\n",
    "    paper_bgcolor=\"rgba(255,255,255,0)\",\n",
    "    showlegend=False,\n",
    "    width=480,\n",
    "    height=360,\n",
    "    margin=dict(l=0,r=0,b=0,t=0,pad=0))\n",
    "fig.show('png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Exists also at least one detail that can make doubts. Columns Length, Width and Height have several hardly visible,  correlated falls. This is because of fact, that the shells was storing and measuring in several  divisions. For each division, one by one, bigger shells was measured at first and then smaller. This proceeding was not intentional, shells was segregated by themself due to Brazil Nut Effect (the size segregation in a vibrated granular material).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. binary form\n",
    "\n",
    "<div style=\"text-align: justify\">Now the data is prepared to compression. Values of each column will be encoded binary to save as many volume as it is possible.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(column: str, frame: pd.DataFrame) -> None:\n",
    "    \"\"\"Prints selected basic information about specified column in a data frame.\"\"\"\n",
    "    print('minimal value:', frame[column].min())\n",
    "    print('maximal value:', frame[column].max())\n",
    "    print('unique values: ', end='')\n",
    "    unique: list[object] = list(frame[column].unique())\n",
    "    for item in unique[:-1]:\n",
    "        print(item, end=', ')\n",
    "    print(unique[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_binary_code(bin_number: str, number_of_digits: int) -> str:\n",
    "    \"\"\"Returns a given binary number without the 0b prefix, optionally leaded by zeros.\"\"\"\n",
    "    return bin_number.removeprefix('0b').zfill(number_of_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(column='Brightness', frame=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "Let\n",
    "\n",
    "- 1.0 -> 2\n",
    "- 0.0 -> 1\n",
    "- nan -> 0\n",
    "  \n",
    "So, only 2 bits are needed to store any of these values.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Brightness'].head())\n",
    "data['Brightness'] += 1\n",
    "data['Brightness'] = data['Brightness'].fillna(0)\n",
    "data['Brightness'] = data['Brightness'].astype(int)\n",
    "data['Brightness'] = data['Brightness'].map(bin)\n",
    "data['Brightness'] = data['Brightness'].map(str)\n",
    "data['Brightness'] = data['Brightness'].map(lambda bin_code: form_binary_code(bin_code,2))\n",
    "print(data['Brightness'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(column='Orientation', frame=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">In this case the situation is better, there is no nan values, so only 1 bit is needed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Orientation'].head())\n",
    "data['Orientation'] = data['Orientation'].astype(int)\n",
    "data['Orientation'] = data['Orientation'].map(bin)\n",
    "data['Orientation'] = data['Orientation'].map(str)\n",
    "data['Orientation'] = data['Orientation'].map(lambda bin_code: form_binary_code(bin_code,1))\n",
    "print(data['Orientation'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Stripes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(column='Stripes', frame=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "There is many more unique values in form <i>xy.0</i> from span <0,96>. Let\n",
    "\n",
    "- nan -> 0\n",
    "- 0.0 -> 1\n",
    "- ...\n",
    "- 96.0 -> 97\n",
    "\n",
    "keeping these values requires at least 7 bits.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Stripes'].head())\n",
    "data['Stripes'] += 1\n",
    "data['Stripes'] = data['Stripes'].fillna(0)\n",
    "data['Stripes'] = data['Stripes'].astype(int)\n",
    "data['Stripes'] = data['Stripes'].map(bin)\n",
    "data['Stripes'] = data['Stripes'].map(str)\n",
    "data['Stripes'] = data['Stripes'].map(lambda bin_code: form_binary_code(bin_code,7))\n",
    "print(data['Stripes'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 AntiStripes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(column='AntiStripes', frame=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "Similar situation can be observed, luckily there is less unique values to encode. Let\n",
    "\n",
    "- nan -> 0\n",
    "- 0.0 -> 1\n",
    "- ...\n",
    "- 13.0 -> 14\n",
    "\n",
    "4 bits are needed.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['AntiStripes'].head())\n",
    "data['AntiStripes'] += 1\n",
    "data['AntiStripes'] = data['AntiStripes'].fillna(0)\n",
    "data['AntiStripes'] = data['AntiStripes'].astype(int)\n",
    "data['AntiStripes'] = data['AntiStripes'].map(bin)\n",
    "data['AntiStripes'] = data['AntiStripes'].map(str)\n",
    "data['AntiStripes'] = data['AntiStripes'].map(lambda bin_code: form_binary_code(bin_code,4))\n",
    "print(data['AntiStripes'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5 CornerAngle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(column='CornerAngle', frame=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "This dataset is a bit different. Apart of nan cells, they take values in form <i>xyz.0</i> from span <90, 163>. As previously, let\n",
    "\n",
    "- nan -> 0\n",
    "\n",
    "The angles have various values but in general, all of them should be measured and rounded to several main values with interval 5.625.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_angle_interval: float = 5.625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Set of the selected angles includes angle 90 degrees, so</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_angles = []\n",
    "for multiplicity in range(0,33):\n",
    "    selected_angles.append(multiplicity*basic_angle_interval)\n",
    "\n",
    "print(selected_angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Now the point is to assign all these angles that are not in the set of selected angles to their closest angles from this set.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_angle(angle: float, selected_angles: list[float]) -> float:\n",
    "    \"\"\"Returns the closest value from the set of selected angles for a given angle.\"\"\"\n",
    "    absolute_distinctions: list[float] = list(map(lambda selected_angle: abs(selected_angle-angle), selected_angles))\n",
    "    return selected_angles[absolute_distinctions.index(min(absolute_distinctions))]\n",
    "\n",
    "# examples\n",
    "print(find_angle(93, selected_angles))\n",
    "print(find_angle(45, selected_angles))\n",
    "print(find_angle(160, selected_angles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace non-selected angles\n",
    "data['CornerAngle'] = data['CornerAngle'].map(lambda angle: find_angle(angle, selected_angles), na_action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">The selected angles reduces the set of available values for dataset CornerAngle. However, all of them are floating numbers which take a lot of volume. The following step enumerates them in ascending order.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_encode(angle: float, threshold: float) -> int:\n",
    "    \"\"\"Returns identifier of an angle.\"\"\"\n",
    "    return int((angle-threshold)/basic_angle_interval) + 1      # 0 reserved for the nan values\n",
    "\n",
    "# examples\n",
    "print(angle_encode(90.00, 90.00))\n",
    "print(angle_encode(157.50, 90.00))\n",
    "print(angle_encode(180.00, 90.00))\n",
    "print(angle_encode(data['CornerAngle'].min(), data['CornerAngle'].min()))\n",
    "print(angle_encode(data['CornerAngle'].max(), data['CornerAngle'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">So, a cell in dataset CornerAngle takes one of numbers from span <0,14> (the nan value or an encoded selected angle). This leads to situation, where <b>only 4 bits are needed to have kept information</b> in any cell in dataset CornerAnge, <b>instead of ~192 bits</b> (24 bytes * 8, but the size of float number depends of hardware). This is a magnificent example of data compression, especially if the dataset would be huge.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['CornerAngle'].head())\n",
    "data['CornerAngle'] = data['CornerAngle']\\\n",
    "    .map(lambda angle: angle_encode(angle, data['CornerAngle'].min()), na_action='ignore')\n",
    "data['CornerAngle'] = data['CornerAngle'].fillna(0)\n",
    "data['CornerAngle'] = data['CornerAngle'].astype(int)\n",
    "data['CornerAngle'] = data['CornerAngle'].map(bin)\n",
    "data['CornerAngle'] = data['CornerAngle'].map(str)\n",
    "data['CornerAngle'] = data['CornerAngle'].map(lambda bin_code: form_binary_code(bin_code,4))\n",
    "print(data['CornerAngle'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6 DilationAngle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(column='DilationAngle',frame=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">In here, it would be good to go the same proceeding as one in the previous section due to similarity between both datasets.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace non-selected angles\n",
    "data['DilationAngle'] = data['DilationAngle'].map(lambda angle: find_angle(angle, selected_angles), na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(angle_encode(data['DilationAngle'].max(), data['DilationAngle'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">The situation is the same as in the previous section namely, a cell in dataset DilationAngle takes one of numbers from span <0,14> (the nan value or an encoded selected angle). So only 4 bits are required to have kept information in any cell in dataset DilationAnge.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['DilationAngle'].head())\n",
    "data['DilationAngle'] = data['DilationAngle']\\\n",
    "    .map(lambda angle: angle_encode(angle, data['DilationAngle'].min()), na_action='ignore')\n",
    "data['DilationAngle'] = data['DilationAngle'].fillna(0)\n",
    "data['DilationAngle'] = data['DilationAngle'].astype(int)\n",
    "data['DilationAngle'] = data['DilationAngle'].map(bin)\n",
    "data['DilationAngle'] = data['DilationAngle'].map(str)\n",
    "data['DilationAngle'] = data['DilationAngle'].map(lambda bin_code: form_binary_code(bin_code,4))\n",
    "print(data['DilationAngle'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.7 Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(column='Length', frame=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">As it can be observed, in this dataset there is no the nan values and all unique of them are in form of <i>x.y</i>. It would be rightly to convert them into integers.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Length'] *= 10\n",
    "\n",
    "print(data['Length'].min())\n",
    "print(data['Length'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Unfortunately, reduction about 11.0 will not allow to reduce the smallest number of required bits. There is 6 of them.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Length'].head())\n",
    "data['Length'] = data['Length'].astype(int)\n",
    "data['Length'] = data['Length'].map(bin)\n",
    "data['Length'] = data['Length'].map(str)\n",
    "data['Length'] = data['Length'].map(lambda bin_code: form_binary_code(bin_code,6))\n",
    "print(data['Length'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.8 Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(column='Width', frame=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">In here it is possible to go as previously however, the nan value is found.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Width'] *= 10\n",
    "\n",
    "print(data['Width'].min())\n",
    "print(data['Width'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">And in this situation, reduction by 12 will not give any benefits, 6 bits are needed at least. Let the nan -> 0.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Width'].head())\n",
    "data['Width'] = data['Width'].fillna(0)\n",
    "data['Width'] = data['Width'].astype(int)\n",
    "data['Width'] = data['Width'].map(bin)\n",
    "data['Width'] = data['Width'].map(str)\n",
    "data['Width'] = data['Width'].map(lambda bin_code: form_binary_code(bin_code,6))\n",
    "print(data['Width'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.9 Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(column='Height', frame=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">In the last dataset, it is possible to have kept information only in 5 bits. There is no the nan values, but each value must be an integer reduced about the minimal value.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Height'].head())\n",
    "data['Height'] *= 10\n",
    "data['Height'] = data['Height'] - data['Height'].min()\n",
    "data['Height'] = data['Height'].astype(int)\n",
    "data['Height'] = data['Height'].map(bin)\n",
    "data['Height'] = data['Height'].map(str)\n",
    "data['Height'] = data['Height'].map(lambda bin_code: form_binary_code(bin_code,5))\n",
    "print(data['Height'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">Finally, the data is ready to be written.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.bin', mode='wb') as file:\n",
    "    buffer: str = ''\n",
    "    frame_size: int = 7\n",
    "\n",
    "    def flush_buffer() -> None:\n",
    "        global buffer\n",
    "        global frame_size\n",
    "        while (len(buffer) // frame_size) >= 1:\n",
    "            file.write(bytes([int(buffer[:frame_size], base=2)]))\n",
    "            buffer = buffer[frame_size:]\n",
    "\n",
    "    for row_index in range(len(data)):\n",
    "        for column_index in range(len(data.columns)):\n",
    "            buffer += data.iloc[row_index, column_index]        # append next bits\n",
    "        flush_buffer()\n",
    "\n",
    "    buffer = buffer.ljust(frame_size,'0')       # complement the last frame\n",
    "    flush_buffer()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8b98e89182393848b269764751de12a768602775d422d11e2018ee05ba3748f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
